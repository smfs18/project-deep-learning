# Classifica√ß√£o de Imagens com Transfer Learning usando VGG16

Neste projeto, eu demonstro uma t√©cnica poderosa e comum em vis√£o computacional: **transfer learning**. Eu utilizei o modelo **VGG16**, pr√©-treinado no extenso dataset ImageNet, e o adaptei para uma nova tarefa espec√≠fica: classificar imagens em uma de seis categorias, alcan√ßando at√© **96% de acur√°cia** no conjunto de valida√ß√£o.

Eu dividi estrategicamente o processo de treinamento em duas fases principais para maximizar o desempenho e a estabilidade:

1.  **Extra√ß√£o de Caracter√≠sticas:** Comecei congelando a base convolucional do modelo VGG16. Isso me permitiu usar suas caracter√≠sticas j√° aprendidas sem alter√°-las. Em seguida, treinei apenas o novo classificador personalizado que adicionei no topo. Isso adaptou rapidamente o modelo para as classes do meu novo dataset.

2.  **Ajuste Fino (Fine-Tuning):** Ap√≥s o treinamento inicial, eu descongelei o modelo inteiro e continuei o treinamento com uma taxa de aprendizado muito baixa. Este passo ajustou ligeiramente os pesos pr√©-treinados para se adequarem melhor √†s nuances do meu dataset espec√≠fico, melhorando ainda mais a acur√°cia.

## ‚öôÔ∏è Tecnologias que Utilizei

* **TensorFlow & Keras:** Para construir e treinar o modelo de deep learning.
* **VGG16:** A rede neural convolucional (CNN) pr√©-treinada que usei como modelo base.
* **ImageDataGenerator:** Para um carregamento de dados eficiente e aumento de dados em tempo real.

## üß† Arquitetura do Modelo

Eu constru√≠ o modelo final empilhando novas camadas sobre a base pr√©-treinada VGG16.

1.  **Modelo Base (VGG16):** Carreguei o modelo VGG16, descartando sua camada de classifica√ß√£o original (`include_top=False`), mas mantendo os pesos aprendidos com o ImageNet.

2.  **Congelamento de Camadas:** Inicialmente, todas as camadas na base VGG16 foram congeladas (`base_model.trainable = False`) para que seus pesos n√£o fossem atualizados durante a primeira fase do treinamento.

3.  **Classificador Personalizado:** Adicionei minha pr√≥pria cabe√ßa de classifica√ß√£o:
    * Uma camada `GlobalAveragePooling2D` para reduzir as dimens√µes espaciais dos mapas de caracter√≠sticas para um √∫nico vetor, reduzindo drasticamente o n√∫mero de par√¢metros.
    * Uma camada final `Dense` com 6 unidades (uma para cada classe de destino) e uma fun√ß√£o de ativa√ß√£o `softmax` para obter a distribui√ß√£o de probabilidade entre as classes.

## üì¶ Prepara√ß√£o e Aumento de Dados

Para tornar o modelo mais robusto e evitar overfitting, apliquei aumento de dados (data augmentation) nas imagens de treinamento em tempo real usando o `ImageDataGenerator`. As transforma√ß√µes aplicadas incluem:

* Rota√ß√µes aleat√≥rias
* Zoom aleat√≥rio
* Deslocamentos horizontais e verticais aleat√≥rios
* Invers√µes horizontais aleat√≥rias

Os dados de valida√ß√£o n√£o foram aumentados; eu apenas reescalei, assim como fiz com os dados de treinamento.

## üöÄ Processo de Treinamento

### Fase 1: Extra√ß√£o de Caracter√≠sticas

Primeiro, compilei o modelo com o otimizador `adam` e a perda `CategoricalCrossentropy`. Eu o treinei por 20 √©pocas. Nesta fase, apenas os pesos das camadas `GlobalAveragePooling2D` e `Dense` foram atualizados. Esta fase de treinamento inicial me permitiu alcan√ßar uma acur√°cia s√≥lida de **94%** no conjunto de valida√ß√£o.

```python
# Congelar o modelo base
base_model.trainable = False

# Compilar o modelo
model.compile(
    optimizer='adam',
    loss=keras.losses.CategoricalCrossentropy(from_logits=False),
    metrics=[keras.metrics.CategoricalAccuracy()]
)

# Treinar apenas as camadas superiores
model.fit(train_it,
          validation_data=valid_it,
          epochs=20)
```

### Fase 2: Ajuste Fino (Fine-Tuning)

Em seguida, descongelei o modelo base para permitir que todos os seus pesos fossem trein√°veis. Recompilei o modelo com uma taxa de aprendizado muito baixa (`0.0001`) e o otimizador `RMSprop`. Usei uma taxa de aprendizado baixa, o que √© crucial para n√£o destruir as caracter√≠sticas valiosas aprendidas com o ImageNet. Treinei o modelo por mais 20 √©pocas. Este passo elevou a acur√°cia de valida√ß√£o para impressionantes **96%**.

```python
# Descongelar o modelo base para permitir o ajuste fino
base_model.trainable = True

# Recompilar com uma taxa de aprendizado muito baixa
model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = 0.0001),
              loss = keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics =[keras.metrics.CategoricalAccuracy()])

# Continuar o treinamento do modelo inteiro
model.fit(train_it,
          validation_data=valid_it,
          epochs=20)
```

## üìà Resultados

A minha abordagem de treinamento em duas fases produziu excelentes resultados:

* **Acur√°cia de Extra√ß√£o de Caracter√≠sticas (Fase 1):** **94%** no conjunto de valida√ß√£o.
* **Acur√°cia de Ajuste Fino (Fase 2):** **96%** no conjunto de valida√ß√£o.

Isso demonstra o poder do transfer learning e como uma segunda fase de ajuste fino pode proporcionar um aumento adicional de desempenho, adaptando as caracter√≠sticas aprendidas mais de perto ao dataset espec√≠fico.

## üìã Como Usar

1.  **Clonar o Reposit√≥rio:**
    ```bash
    git clone <url-do-seu-repositorio>
    cd <nome-do-repositorio>
    ```

2.  **Organizar os Dados:** Certifique-se de que seu conjunto de dados de imagem esteja estruturado da seguinte maneira:
    ```
    dataset/
    ‚îú‚îÄ‚îÄ train/
    ‚îÇ   ‚îú‚îÄ‚îÄ classe_1/
    ‚îÇ   ‚îî‚îÄ‚îÄ classe_2/
    ‚îî‚îÄ‚îÄ valid/
        ‚îú‚îÄ‚îÄ classe_1/
        ‚îî‚îÄ‚îÄ classe_2/
    ```

3.  **Atualizar os Caminhos dos Arquivos:** No script Python, altere os caminhos nas chamadas `flow_from_directory` para que apontem para seus diret√≥rios `train` e `valid`.
    ```python
    train_it = datagen_train.flow_from_directory(
        'caminho/para/seu/dataset/train',
        # ... outros par√¢metros
    )
    
    valid_it = datagen_valid.flow_from_directory(
        'caminho/para/seu/dataset/valid',
        # ... outros par√¢metros
    )
    ```

4.  **Executar** o script para iniciar o processo de treinamento.
